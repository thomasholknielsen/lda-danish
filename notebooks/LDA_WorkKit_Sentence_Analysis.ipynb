{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Analysis\n",
    "This workbook is to be employeed during analysis of the text\n",
    "\n",
    "Set the following:\n",
    "- connection info and \n",
    "- query to import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import moduls and \n",
    "# change directory to make it relative to top level moduls\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules to be used in this package\n",
    "import pandas as pd\n",
    "from utils.lipht_data import getEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the connection to the server\n",
    "engine = getEngine('LIPHT-VM-01','Akademikernes_MSCRM_Addition')\n",
    "query=\"\"\"\n",
    "        SELECT [ThreadID]\n",
    "                        ,[ThreadTopic]\n",
    "                        ,[SignalMessageID]\n",
    "                        ,[SignalSource] AS ThreadInitiatedBy\n",
    "                        ,[SignalMessageBodyClean]\n",
    "                        ,[IsSystemGenerated]\n",
    "                    FROM [Akademikernes_MSCRM_Addition].[out].[vw_LDA_MessagesALL]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df_scope = pd.read_sql(query, engine).copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section work has been done in order to do sentence tagging based on conventional danish way of formulating messages. This should be adapted into the scope of the project that you are working on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from utils.lipht_regex import re_accronyms, re_system, re_keyconcepts, re_lemma, re_remove\n",
    "\n",
    "sentence_cleanup = {\n",
    "    r'\\xa0\\n': '\\n',\n",
    "    r'\\xa0': ' ',\n",
    "    r'(\\r\\n)': ' ',\n",
    "    r'(?=[\\?])\\?+(\\s)?(?<=[\\?])': '?\\n',\n",
    "    r'\\sd\\.': 'den',\n",
    "    r'(?<=den\\s\\d{2})\\.(?=(,|\\s))|(?<=den\\s\\d{1})\\.(?=(,|\\s))|(?<=senest\\s\\d{2})\\.(?=(,|\\s))|(?<=senest\\s\\d{1})\\.(?=(,|\\s))': '', # replace '.' after den 23. or senest 23.\n",
    "    r'(?<=\\s\\d{2})\\.|(?<=\\s\\d{1})\\.|(?<=\\s\\d{2}\\.\\d{2})\\.|(?<=\\s\\d{1}\\.\\d{2})\\.': '-', # handles 23.6 and 1.6 to '-' instead of '.'\n",
    "    r'(?<=(den|til)\\s\\d{2})\\.': '-', # swap 27.06 to 27-06\n",
    "}\n",
    "\n",
    "def blobtolist(blob):  \n",
    "    list_sent = [s.strip() for s in re.split(r'\\n', blob)] # Create a list by every linebreak\n",
    "    list_sent = list(filter(None,list_sent)) # Remove all empty lists\n",
    "    list_sent = [s.strip('.') for s in list_sent] # Remove '.' from sentences in each list\n",
    "\n",
    "    final = []\n",
    "    for i in list_sent:\n",
    "        temp = re.split(r'\\.',i)\n",
    "        for i in temp:\n",
    "            final.append(i.strip())\n",
    "    return final\n",
    "\n",
    "def tag_sentences(list_sentences):\n",
    "    def find_matches(item):\n",
    "        tags = {\n",
    "            r'.*\\?': 'QUESTION',\n",
    "            r'(til|til\\s*\\svedkom|kære|hej|hejsa|goddag|godmorgen|hello|hi|dear)': 'GREETING',\n",
    "            r'.*(bekræfter.*.hermed.*.korrekt)': 'CONFIRMATION',\n",
    "            r'\\b(tak)': 'POSITIVE FEEDBACK',\n",
    "            r'.*(håber.*.hjælpe)': 'REQUEST HELP',\n",
    "            r'.*(kan i tjekke.*\\?)': 'REQUEST X CHECKED',\n",
    "            r'.*(har i mulighed.*\\?)': 'REQUEST FOR ACTION',\n",
    "            r'.*(vedhæft(ede|et|er|e)?|fil(type(r)|er))': 'ATTACHMENT',\n",
    "            r'([0-9]+\\s){4}|(([0-9]){8})': 'PHONE NUMBER',\n",
    "            r'(på\\sforhånd\\stak)|(((jeg|du)\\sønske(s|r\\s)(dig)?|(hav))\\s)?(en\\s)?((fortsat|rigtig)\\s)?god(t)?\\s(weekend|dag|ferie|jul|nytår|påske)|(held\\sog\\slykke\\s(fremover)?)|(god\\sarbejdslyst)': 'POLITE ENDING',\n",
    "            r'(med\\svenlig\\shilsen|de\\sbedste\\shilsner|bedste\\shilsener|bedste\\shilsner|kærlig\\shilsen|dbh|venlig\\shilsen|mvh|m\\.v\\.h\\.|vh|hilsen|venlig|bh|best\\sregards|with\\skind\\sregards|kind\\sregards|with\\sregards|regards|kh).*': 'ENDING',\n",
    "            r'(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])?': 'URL',\n",
    "            r'([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])?': 'URL',\n",
    "            r'(?<=\\s)(\\w)*@{1}(\\w)*\\.(\\w){2,3}(?=\\s)': 'EMAIL',\n",
    "            r'\\b(ak(\\s)?(\\d{3}))': 'AK FORM',\n",
    "            r'\\b(ar(\\s)?(\\d{3}))': 'AR FORM',\n",
    "            r'(sent\\sfrom\\smy\\s).*':'DEVICE INFORMATION',\n",
    "            }\n",
    "        for k in tags:\n",
    "            if re.match(k, item):\n",
    "                return tags[k]\n",
    "\n",
    "    matches = []\n",
    "    used_tags = []\n",
    "    for sentence in list_sentences:\n",
    "        sentence = sentence.lower().strip()\n",
    "        if 'ENDING' in used_tags:\n",
    "            # CREATE CHECK FOR things after ENDING\n",
    "            matches.append((sentence,'AFTER ENDING'))\n",
    "        elif find_matches(sentence) is None:\n",
    "            matches.append((sentence,'CONTENT'))\n",
    "        else:\n",
    "            used_tags.append(find_matches(sentence))\n",
    "            matches.append((sentence, find_matches(sentence)))\n",
    "            next\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section we are extracing only the text column to be used for further analysis. This will be followed by applying the functions from above on the target_col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'SignalMessageBodyClean'#'FirstMemberMessageBody'#'FirstResponseFromAKAToMemberMessageBody'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences = df_scope[[target_col]].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_sentences['clean_blob'] = df_sentences[target_col].apply(clean_blob) # Make list of strings\n",
    "df_sentences['clean_blob'] = df_sentences[target_col].str.lower()\n",
    "df_sentences['clean_blob'] = df_sentences['clean_blob'].replace(regex=re_accronyms) # Make list of strings\n",
    "df_sentences['clean_blob'] = df_sentences['clean_blob'].replace(regex=sentence_cleanup) # Make list of strings\n",
    "df_sentences['sentence_list'] = df_sentences['clean_blob'].apply(blobtolist) # Make list of strings\n",
    "df_sentences['tagged_list'] = df_sentences['sentence_list'].apply(tag_sentences) # Tag each string in list -> tuples\n",
    "df_sentences['list_of_tags'] = df_sentences['tagged_list'].apply(lambda df: [(t[1], t[0]) for t in df]) # swap order of k, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See a sample of the what was produced by our fuctions - 4 new columns. \n",
    "- clean_blob - text preperation \n",
    "- sentence_list - the text split into sentences\n",
    "- tagged_list - the text split into tuples of sentences and their tag\n",
    "- list_of_tags - same as above, only swapped tupples\n",
    "\n",
    "Run multiple times to see new samples (hint use: CTRL+ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample\n",
      "[['du har optjent feriedagpenge, som du kan søge om til ferieåret 2018/2019', 'læs nærmere i brevet, hvor mange dage med feriedagpenge du har optjent, og hvordan du søger om dem']]\n",
      "\n",
      "Sample - with sentence tagging\n",
      "[[('CONTENT', 'du har optjent feriedagpenge, som du kan søge om til ferieåret 2018/2019'), ('CONTENT', 'læs nærmere i brevet, hvor mange dage med feriedagpenge du har optjent, og hvordan du søger om dem')]]\n",
      "\n",
      "Sample - cleaned text\n",
      "du har optjent feriedagpenge, som du kan søge om til ferieåret 2018/2019. læs nærmere i brevet, hvor mange dage med feriedagpenge du har optjent, og hvordan du søger om dem.\n"
     ]
    }
   ],
   "source": [
    "# Sample of function results\n",
    "sample = df_sentences.sample(1).index \n",
    "print('\\nSample')\n",
    "print([i for i in df_sentences['sentence_list'][sample]])\n",
    "print('\\nSample - with sentence tagging')\n",
    "print([i for i in df_sentences['list_of_tags'][sample]])\n",
    "print('\\nSample - cleaned text')\n",
    "print(''.join(df_sentences['clean_blob'][sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df_sentences['list_of_tags'] # Take the single column\n",
    "df_list = df_count.tolist() # Convert dataframe to list of lists with tuples\n",
    "tag_sentence_pair = [item for sublist in df_list for item in sublist] # convert to list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from tag_sentence_pair\n",
    "headers = ['tag', 'sentence']\n",
    "df = pd.DataFrame(tag_sentence_pair, columns=headers)\n",
    "df_sum = df.groupby(['sentence','tag']).size().reset_index(name='counts').sort_values(by=['counts'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_sum = df_sum[df_sum['counts']>1]\n",
    "df_sum['column'] = target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag</th>\n",
       "      <th>counts</th>\n",
       "      <th>column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1611976</th>\n",
       "      <td>wohlsch@gmail</td>\n",
       "      <td>AFTER ENDING</td>\n",
       "      <td>1</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sentence           tag  counts                  column\n",
       "1611976  wohlsch@gmail  AFTER ENDING       1  SignalMessageBodyClean"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tag</th>\n",
       "      <th>counts</th>\n",
       "      <th>column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>671277</th>\n",
       "      <td>håber at i kan hjælpe</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>18</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671283</th>\n",
       "      <td>håber at i kan hjælpe mig</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>15</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672460</th>\n",
       "      <td>håber det kunne hjælpe</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>74</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673477</th>\n",
       "      <td>håber du kan hjælpe</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>31</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673490</th>\n",
       "      <td>håber du kan hjælpe mig</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>17</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673918</th>\n",
       "      <td>håber i kan hjælpe</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>304</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673927</th>\n",
       "      <td>håber i kan hjælpe :)</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>17</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674023</th>\n",
       "      <td>håber i kan hjælpe mig</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>157</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958478</th>\n",
       "      <td>jeg håber at i kan hjælpe</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>15</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961414</th>\n",
       "      <td>jeg håber i kan hjælpe</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>80</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961458</th>\n",
       "      <td>jeg håber i kan hjælpe mig</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>77</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964088</th>\n",
       "      <td>jeg håber, at i kan hjælpe</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>24</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964105</th>\n",
       "      <td>jeg håber, at i kan hjælpe mig</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>20</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965055</th>\n",
       "      <td>jeg håber, i kan hjælpe</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>19</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965069</th>\n",
       "      <td>jeg håber, i kan hjælpe mig</td>\n",
       "      <td>REQUEST HELP</td>\n",
       "      <td>25</td>\n",
       "      <td>SignalMessageBodyClean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence           tag  counts  \\\n",
       "671277           håber at i kan hjælpe  REQUEST HELP      18   \n",
       "671283       håber at i kan hjælpe mig  REQUEST HELP      15   \n",
       "672460          håber det kunne hjælpe  REQUEST HELP      74   \n",
       "673477             håber du kan hjælpe  REQUEST HELP      31   \n",
       "673490         håber du kan hjælpe mig  REQUEST HELP      17   \n",
       "673918              håber i kan hjælpe  REQUEST HELP     304   \n",
       "673927           håber i kan hjælpe :)  REQUEST HELP      17   \n",
       "674023          håber i kan hjælpe mig  REQUEST HELP     157   \n",
       "958478       jeg håber at i kan hjælpe  REQUEST HELP      15   \n",
       "961414          jeg håber i kan hjælpe  REQUEST HELP      80   \n",
       "961458      jeg håber i kan hjælpe mig  REQUEST HELP      77   \n",
       "964088      jeg håber, at i kan hjælpe  REQUEST HELP      24   \n",
       "964105  jeg håber, at i kan hjælpe mig  REQUEST HELP      20   \n",
       "965055         jeg håber, i kan hjælpe  REQUEST HELP      19   \n",
       "965069     jeg håber, i kan hjælpe mig  REQUEST HELP      25   \n",
       "\n",
       "                        column  \n",
       "671277  SignalMessageBodyClean  \n",
       "671283  SignalMessageBodyClean  \n",
       "672460  SignalMessageBodyClean  \n",
       "673477  SignalMessageBodyClean  \n",
       "673490  SignalMessageBodyClean  \n",
       "673918  SignalMessageBodyClean  \n",
       "673927  SignalMessageBodyClean  \n",
       "674023  SignalMessageBodyClean  \n",
       "958478  SignalMessageBodyClean  \n",
       "961414  SignalMessageBodyClean  \n",
       "961458  SignalMessageBodyClean  \n",
       "964088  SignalMessageBodyClean  \n",
       "964105  SignalMessageBodyClean  \n",
       "965055  SignalMessageBodyClean  \n",
       "965069  SignalMessageBodyClean  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum[df_sum['tag']=='REQUEST HELP'].head(15).sort_values(by=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1633966, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sum.to_sql(name='sentence_count'.format(target_col) ,con=engine , schema='input', if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sentences['FirstMemberMessageBody'].sample(1).index[0]\n",
    "test = df_sentences['FirstMemberMessageBody'][sample]\n",
    "l = tag_sentences(blobtolist(test))\n",
    "test, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(t[1], t[0]) for t in l] # swap tuple elements\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [[t[1], t[0]] for t in l]\n",
    "headers = ['sentence', 'tag']\n",
    "df = pd.DataFrame(table, columns=headers)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for k, v in l:\n",
    "    d[k] = d.get(k, ()) + (v,)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d, index['i'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "test = re.sub('(vedhæft(ede|et|er|e)?)','snakket','jeg har vedhæfte følgende dokument')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(r'\\b(hold(et|er|et|e|t)?)','holde','Både holdet, hold og holder skulle skiftes') #r'\\b(holdet|holder|holde|hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aka-diagnostic]",
   "language": "python",
   "name": "conda-env-aka-diagnostic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
