{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modul import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\akademikernes_diagnostic\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Common\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text processing\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "# Visualization modules\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model modules\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer#, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.corpora import MmCorpus\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "from gensim.models import phrases, word2vec\n",
    "\n",
    "# Remove unnecessary warnings\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lipht_lda import df_lda_preprocessing, lda_preprocess_string, df_lda_features, get_lda_topics, lda_predict_df, lda_predict_string, document_to_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_pickle('data/AKA_rawdata.pkl')\n",
    "df_import = df_raw.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_import = pd.read_pickle('data/AKA_rawdata_df_lda_preprocessed.pkl')\n",
    "df_import = pd.read_pickle('data/AKA_rawdata_with_language.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'df_B'\n",
    "n_gram = 2\n",
    "sample_size= 10000\n",
    "no_words= 5000\n",
    "no_below= 20 # filter out tokens that appear in less than 15 documents\n",
    "random_state=1\n",
    "research_scope = 'Udbetaling'\n",
    "num_topics = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ThreadID</th>\n",
       "      <th>ThreadCreatedFromLetter</th>\n",
       "      <th>ThreadTotalMessageCount</th>\n",
       "      <th>ThreadStatus</th>\n",
       "      <th>ThreadSubject</th>\n",
       "      <th>ThreadResponsibleDepartment</th>\n",
       "      <th>ThreadResponsibleDepartmentTeam</th>\n",
       "      <th>ThreadHasInteraction</th>\n",
       "      <th>ThreadInitiatedBy</th>\n",
       "      <th>ThreadMessageRank</th>\n",
       "      <th>...</th>\n",
       "      <th>text_Exclamationmarks</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>bow</th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_probability</th>\n",
       "      <th>pred_index</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3F206D77-DFB5-E811-82B4-0050569118B0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuldført</td>\n",
       "      <td>Du er tilmeldt et arrangement</td>\n",
       "      <td>Jobmatch</td>\n",
       "      <td>Logistik</td>\n",
       "      <td>0</td>\n",
       "      <td>AKA</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[din, booking, er, på, plads, vi, bekræfter, a...</td>\n",
       "      <td>[booking, plads, bekræfter, tilmeldt, studieku...</td>\n",
       "      <td>[booking, plads, bekræfter, tilmeldt, studieku...</td>\n",
       "      <td>[book, plad, bekræfter, tilmeldt, studiekursu,...</td>\n",
       "      <td>[(43, 1), (46, 1), (104, 1), (142, 1), (146, 2...</td>\n",
       "      <td>[0.9617956, 0, Danish]</td>\n",
       "      <td>0.961796</td>\n",
       "      <td>0</td>\n",
       "      <td>Danish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A4B4F902-E4B5-E811-82B4-0050569118B0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuldført</td>\n",
       "      <td>Du er tilmeldt et arrangement</td>\n",
       "      <td>Jobmatch</td>\n",
       "      <td>Logistik</td>\n",
       "      <td>0</td>\n",
       "      <td>AKA</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[din, booking, er, på, plads, vi, bekræfter, a...</td>\n",
       "      <td>[booking, plads, bekræfter, tilmeldt, talent, ...</td>\n",
       "      <td>[booking, plads, bekræfter, tilmeldt, talent, ...</td>\n",
       "      <td>[book, plad, bekræfter, tilmeldt, talent, tilr...</td>\n",
       "      <td>[(43, 1), (46, 1), (142, 1), (148, 1), (149, 1...</td>\n",
       "      <td>[0.95124453, 0, Danish]</td>\n",
       "      <td>0.951245</td>\n",
       "      <td>0</td>\n",
       "      <td>Danish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C7AAAE22-E4B5-E811-82B4-0050569118B0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuldført</td>\n",
       "      <td>Du er tilmeldt et arrangement</td>\n",
       "      <td>Jobmatch</td>\n",
       "      <td>Logistik</td>\n",
       "      <td>0</td>\n",
       "      <td>AKA</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[din, booking, er, på, plads, vi, bekræfter, a...</td>\n",
       "      <td>[booking, plads, bekræfter, tilmeldt, talent, ...</td>\n",
       "      <td>[booking, plads, bekræfter, tilmeldt, talent, ...</td>\n",
       "      <td>[book, plad, bekræfter, tilmeldt, talent, tilr...</td>\n",
       "      <td>[(43, 1), (46, 1), (142, 1), (148, 1), (149, 1...</td>\n",
       "      <td>[0.9569702, 0, Danish]</td>\n",
       "      <td>0.956970</td>\n",
       "      <td>0</td>\n",
       "      <td>Danish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>447AC33F-E6B5-E811-82B4-0050569118B0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuldført</td>\n",
       "      <td>Du er nu afmeldt ventelisten til LinkedIn</td>\n",
       "      <td>Jobmatch</td>\n",
       "      <td>Logistik</td>\n",
       "      <td>0</td>\n",
       "      <td>AKA</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[du, er, nu, afmeldt, ventelisten, til, linked...</td>\n",
       "      <td>[afmeldt, ventelisten, linkedin, blevet, tilbu...</td>\n",
       "      <td>[afmeldt, ventelisten, linkedin, blevet, tilbu...</td>\n",
       "      <td>[afmeldt, ventelisten, linkedin, blevet, tilbu...</td>\n",
       "      <td>[(8, 1), (13, 1), (36, 1), (43, 1), (149, 1), ...</td>\n",
       "      <td>[0.9625676, 0, Danish]</td>\n",
       "      <td>0.962568</td>\n",
       "      <td>0</td>\n",
       "      <td>Danish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80A4A5A3-EAB5-E811-82B4-0050569118B0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuldført</td>\n",
       "      <td>Du er nu på venteliste til Mindfulness</td>\n",
       "      <td>Jobmatch</td>\n",
       "      <td>Logistik</td>\n",
       "      <td>0</td>\n",
       "      <td>AKA</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[salvador, rodriguez, du, er, nu, på, ventelis...</td>\n",
       "      <td>[salvador, rodriguez, ventelisten, mindfulness...</td>\n",
       "      <td>[salvador, rodriguez, ventelisten, mindfulness...</td>\n",
       "      <td>[salvador, rodriguez, ventelisten, mind, septe...</td>\n",
       "      <td>[(11, 1), (43, 1), (62, 1), (146, 1), (149, 1)]</td>\n",
       "      <td>[0.93669635, 0, Danish]</td>\n",
       "      <td>0.936696</td>\n",
       "      <td>0</td>\n",
       "      <td>Danish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ThreadID  ThreadCreatedFromLetter  \\\n",
       "0  3F206D77-DFB5-E811-82B4-0050569118B0                        0   \n",
       "1  A4B4F902-E4B5-E811-82B4-0050569118B0                        0   \n",
       "2  C7AAAE22-E4B5-E811-82B4-0050569118B0                        0   \n",
       "3  447AC33F-E6B5-E811-82B4-0050569118B0                        0   \n",
       "4  80A4A5A3-EAB5-E811-82B4-0050569118B0                        0   \n",
       "\n",
       "   ThreadTotalMessageCount ThreadStatus  \\\n",
       "0                        1     Fuldført   \n",
       "1                        1     Fuldført   \n",
       "2                        1     Fuldført   \n",
       "3                        1     Fuldført   \n",
       "4                        1     Fuldført   \n",
       "\n",
       "                               ThreadSubject ThreadResponsibleDepartment  \\\n",
       "0              Du er tilmeldt et arrangement                    Jobmatch   \n",
       "1              Du er tilmeldt et arrangement                    Jobmatch   \n",
       "2              Du er tilmeldt et arrangement                    Jobmatch   \n",
       "3  Du er nu afmeldt ventelisten til LinkedIn                    Jobmatch   \n",
       "4     Du er nu på venteliste til Mindfulness                    Jobmatch   \n",
       "\n",
       "  ThreadResponsibleDepartmentTeam  ThreadHasInteraction ThreadInitiatedBy  \\\n",
       "0                        Logistik                     0               AKA   \n",
       "1                        Logistik                     0               AKA   \n",
       "2                        Logistik                     0               AKA   \n",
       "3                        Logistik                     0               AKA   \n",
       "4                        Logistik                     0               AKA   \n",
       "\n",
       "   ThreadMessageRank     ...      text_Exclamationmarks  \\\n",
       "0                  1     ...                          0   \n",
       "1                  1     ...                          0   \n",
       "2                  1     ...                          0   \n",
       "3                  1     ...                          0   \n",
       "4                  1     ...                          0   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [din, booking, er, på, plads, vi, bekræfter, a...   \n",
       "1  [din, booking, er, på, plads, vi, bekræfter, a...   \n",
       "2  [din, booking, er, på, plads, vi, bekræfter, a...   \n",
       "3  [du, er, nu, afmeldt, ventelisten, til, linked...   \n",
       "4  [salvador, rodriguez, du, er, nu, på, ventelis...   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  [booking, plads, bekræfter, tilmeldt, studieku...   \n",
       "1  [booking, plads, bekræfter, tilmeldt, talent, ...   \n",
       "2  [booking, plads, bekræfter, tilmeldt, talent, ...   \n",
       "3  [afmeldt, ventelisten, linkedin, blevet, tilbu...   \n",
       "4  [salvador, rodriguez, ventelisten, mindfulness...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  [booking, plads, bekræfter, tilmeldt, studieku...   \n",
       "1  [booking, plads, bekræfter, tilmeldt, talent, ...   \n",
       "2  [booking, plads, bekræfter, tilmeldt, talent, ...   \n",
       "3  [afmeldt, ventelisten, linkedin, blevet, tilbu...   \n",
       "4  [salvador, rodriguez, ventelisten, mindfulness...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  [book, plad, bekræfter, tilmeldt, studiekursu,...   \n",
       "1  [book, plad, bekræfter, tilmeldt, talent, tilr...   \n",
       "2  [book, plad, bekræfter, tilmeldt, talent, tilr...   \n",
       "3  [afmeldt, ventelisten, linkedin, blevet, tilbu...   \n",
       "4  [salvador, rodriguez, ventelisten, mind, septe...   \n",
       "\n",
       "                                                 bow               prediction  \\\n",
       "0  [(43, 1), (46, 1), (104, 1), (142, 1), (146, 2...   [0.9617956, 0, Danish]   \n",
       "1  [(43, 1), (46, 1), (142, 1), (148, 1), (149, 1...  [0.95124453, 0, Danish]   \n",
       "2  [(43, 1), (46, 1), (142, 1), (148, 1), (149, 1...   [0.9569702, 0, Danish]   \n",
       "3  [(8, 1), (13, 1), (36, 1), (43, 1), (149, 1), ...   [0.9625676, 0, Danish]   \n",
       "4    [(11, 1), (43, 1), (62, 1), (146, 1), (149, 1)]  [0.93669635, 0, Danish]   \n",
       "\n",
       "   pred_probability  pred_index  pred_label  \n",
       "0          0.961796           0      Danish  \n",
       "1          0.951245           0      Danish  \n",
       "2          0.956970           0      Danish  \n",
       "3          0.962568           0      Danish  \n",
       "4          0.936696           0      Danish  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataset for method B\n",
    "# Process 1st MemberMessage, then\n",
    "# Concatenate with Subject\n",
    "df_B = df_import.copy(deep=True)\n",
    "df_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1101095, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87757, 31)\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_B = df_B[(df_B['ThreadStatus']=='Fuldført') & (df_B['ThreadMessageDirection']=='Indgående') & (df_B['ThreadMessageIsFirstMemberMessage']==1) & (df_B['ThreadTotalMessageCount']>1) & (df_B['ThreadHasInteraction']>=1) & (df_B['ThreadResponsibleDepartmentTeam']=='Udbetalingsteam') & (df_B['pred_label']=='Danish')]\n",
    "df_B = df_B[(df_B['ThreadStatus']=='Fuldført') & (df_B['ThreadMessageDirection']=='Indgående') & (df_B['ThreadMessageIsFirstMemberMessage']==1) & (df_B['ThreadResponsibleDepartmentTeam'].str.contains('Udbetalingsteam')==True) & (df_B['pred_label']=='Danish')]\n",
    "print(df_B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B.ThreadResponsibleDepartmentTeam.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_lda_preprocessing(df_B,'ThreadMessageText',n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreadID                              0\n",
       "ThreadCreatedFromLetter               0\n",
       "ThreadTotalMessageCount               0\n",
       "ThreadStatus                          0\n",
       "ThreadSubject                        12\n",
       "ThreadResponsibleDepartment           0\n",
       "ThreadResponsibleDepartmentTeam       0\n",
       "ThreadHasInteraction                  0\n",
       "ThreadInitiatedBy                     0\n",
       "ThreadMessageRank                     0\n",
       "ThreadMessageIsFirstMemberMessage     0\n",
       "ThreadMessageIsFirstAKAMessage        0\n",
       "ThreadMessageID                       0\n",
       "ThreadMessageDirection                0\n",
       "ThreadMessageDateCreated              0\n",
       "ThreadMessageText                     0\n",
       "text                                  0\n",
       "text_CharCount                        0\n",
       "text_LessThan5000                     0\n",
       "text_Questionmarks                    0\n",
       "text_1Question                        0\n",
       "text_Exclamationmarks                 0\n",
       "tokenized_text                        0\n",
       "stopwords_removed                     0\n",
       "lemmatized_text                       0\n",
       "stemmed_text                          0\n",
       "bow                                   0\n",
       "prediction                            0\n",
       "pred_probability                      0\n",
       "pred_index                            0\n",
       "pred_label                            0\n",
       "text_WordCount                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87757, 32)\n"
     ]
    }
   ],
   "source": [
    "print(df_B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B.to_pickle('data/df_B.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Requests\n",
    "Messages are either\n",
    "- Incoming (from members) or\n",
    "- Outgoing (from aka)\n",
    "All messeages have\n",
    "- subject_field and\n",
    "- message_field\n",
    "\n",
    "In the following we will analyze the different splits of data, with regards to the above:\n",
    "- Incoming_subject\n",
    "- Incoming_message\n",
    "- Outgoing_subject\n",
    "- Outgoing_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request Analysis: subject_member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the data, and print rows, columns\n",
    "df_scope = pd.read_pickle('data/{}.pkl'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87757, 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scope.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udbetaling_topics-20_Sample-10000_WordCount-5000_RandomState-1_dataset-df_B\n"
     ]
    }
   ],
   "source": [
    "data_scope_name = research_scope +'_topics-'+ str(num_topics) +'_Sample-'+str(sample_size) +'_WordCount-'+str(no_words) +'_RandomState-'+str(random_state)+'_dataset-'+ dataset\n",
    "print(data_scope_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dictionary and top words\n",
    "\n",
    "##### Parameters:\t\n",
    "- **no_below** (int, optional) – Keep tokens which are contained in at least no_below documents.\n",
    "- **no_above** (float, optional) – Keep tokens which are contained in no more than no_above documents (fraction of total corpus size, not an absolute number).\n",
    "- **keep_n** (int, optional) – Keep only the first keep_n most frequent tokens.\n",
    "- **keep_tokens** (iterable of str) – Iterable of tokens that must stay in dictionary after filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 579249 words.\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create dictionary with words from df_scope (the total dataset)\n",
    "dictionary = Dictionary(documents=df_scope.stemmed_text.values)\n",
    "print(\"Found {} words.\".format(len(dictionary.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left with 5000 words.\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# dictionary.filter_extremes(no_above=0.8, no_below=3)\n",
    "dictionary.filter_extremes(no_below=no_below, keep_n=no_words)\n",
    "\n",
    "dictionary.compactify()  # Reindexes the remaining words after filtering\n",
    "print(\"Left with {} words.\".format(len(dictionary.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_bow(df, dictionary):\n",
    "    \"Make a BoW for every Besked\"\n",
    "    df['bow'] = list(map(lambda doc: dictionary.doc2bow(doc), df.stemmed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Make a BoW for every Besked\n",
    "document_to_bow(df_scope, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Sample of Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope_lda_sample = df_scope.sample(sample_size, random_state=random_state)\n",
    "scope_lda_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ThreadID', 'ThreadCreatedFromLetter', 'ThreadTotalMessageCount',\n",
       "       'ThreadStatus', 'ThreadSubject', 'ThreadResponsibleDepartment',\n",
       "       'ThreadResponsibleDepartmentTeam', 'ThreadHasInteraction',\n",
       "       'ThreadInitiatedBy', 'ThreadMessageRank',\n",
       "       'ThreadMessageIsFirstMemberMessage',\n",
       "       'ThreadMessageIsFirstAKAMessage', 'ThreadMessageID',\n",
       "       'ThreadMessageDirection', 'ThreadMessageDateCreated',\n",
       "       'ThreadMessageText', 'text', 'text_CharCount', 'text_LessThan5000',\n",
       "       'text_Questionmarks', 'text_1Question', 'text_Exclamationmarks',\n",
       "       'tokenized_text', 'stopwords_removed', 'lemmatized_text',\n",
       "       'stemmed_text', 'bow', 'prediction', 'pred_probability',\n",
       "       'pred_index', 'pred_label', 'text_WordCount'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope_lda_sample.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ThreadID</th>\n",
       "      <th>ThreadMessageID</th>\n",
       "      <th>ThreadSubject</th>\n",
       "      <th>ThreadMessageText</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264513</th>\n",
       "      <td>06A111C2-D8BF-E811-864D-005056AD2D14</td>\n",
       "      <td>12A111C2-D8BF-E811-864D-005056AD2D14</td>\n",
       "      <td>Lukning af virksomhed - Att. Steen Skivinger</td>\n",
       "      <td>\\nHej Steen\\nVi talte sammen i tlf her i formi...</td>\n",
       "      <td>vi talte sammen i tlf her i formiddag, jeg har...</td>\n",
       "      <td>[blot, jeg_har, sammen, her, lå_som, denne_bes...</td>\n",
       "      <td>[blot, jeg_har, lå_som, denne_besked, info, be...</td>\n",
       "      <td>[blot, jeg_har, lå_som, denne_besked, info, be...</td>\n",
       "      <td>[blot, jeg_har, lå_som, denne_besked, info, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919935</th>\n",
       "      <td>AB057000-E7D8-E711-B45B-005056AD2D14</td>\n",
       "      <td>B5057000-E7D8-E711-B45B-005056AD2D14</td>\n",
       "      <td>Din ret til supplerende dagpenge udløber</td>\n",
       "      <td>\\nKære Karin Arge\\nTak for dit brev. Det er je...</td>\n",
       "      <td>arge\\ntak for dit brev. det er jeg ked af at h...</td>\n",
       "      <td>[heller, fra_akassen, påtænker, kunne_anvende,...</td>\n",
       "      <td>[fra_akassen, påtænker, kunne_anvende, forbind...</td>\n",
       "      <td>[fra_akassen, påtænker, kunne_anvende, forbind...</td>\n",
       "      <td>[fra_akas, påtænk, kunne_anv, forbindelse_vøns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561623</th>\n",
       "      <td>E8C83BD6-2C15-E711-AC9F-005056AD2D14</td>\n",
       "      <td>F9C83BD6-2C15-E711-AC9F-005056AD2D14</td>\n",
       "      <td>Ferie dagepenge optjeningsblanket.</td>\n",
       "      <td>\\n\\nHermed følger besked omkring mine ferie da...</td>\n",
       "      <td>hermed følger besked omkring mine ferie dagpen...</td>\n",
       "      <td>[dagpenge_fra, følger_besked, omkring_mine, fe...</td>\n",
       "      <td>[dagpenge_fra, følger_besked, omkring_mine, fe...</td>\n",
       "      <td>[dagpenge_fra, følger_besked, omkring_mine, fe...</td>\n",
       "      <td>[dagpenge_fra, følger_besked, omkring_min, fer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592345</th>\n",
       "      <td>79CEC772-D92F-E711-AC9F-005056AD2D14</td>\n",
       "      <td>80CEC772-D92F-E711-AC9F-005056AD2D14</td>\n",
       "      <td>Dagepengesats</td>\n",
       "      <td>\\nHej,\\nMin ledighedserklæring er netop godken...</td>\n",
       "      <td>min ledighedserklæring er netop godkendt med e...</td>\n",
       "      <td>[fuldtidsarbejde, er_årsagen, sidste, netop, i...</td>\n",
       "      <td>[fuldtidsarbejde, er_årsagen, sidste, netop, i...</td>\n",
       "      <td>[fuldtidsarbejde, er_årsagen, sidste, netop, i...</td>\n",
       "      <td>[fuldtidsarbejd, er_årsag, sidst, netop, ikke_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014822</th>\n",
       "      <td>59D28CD8-6468-E711-BE8E-005056AD2D14</td>\n",
       "      <td>66D28CD8-6468-E711-BE8E-005056AD2D14</td>\n",
       "      <td>Nyt brev: Udfyld en blanket om din deltagelse ...</td>\n",
       "      <td>\\n\\n230854-1625\\n\\n\\nKære A-kasse\\n\\n\\nEfter l...</td>\n",
       "      <td>efter læsning af regelsæt har jeg vurderet , a...</td>\n",
       "      <td>[indbakke, ikke_kan, arbejde_mvh, pension, aka...</td>\n",
       "      <td>[indbakke, ikke_kan, arbejde_mvh, pension, i_u...</td>\n",
       "      <td>[indbakke, ikke_kan, arbejde_mvh, pension, i_u...</td>\n",
       "      <td>[indbak, ikke_kan, arbejde_mvh, pension, i_und...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ThreadID  \\\n",
       "264513   06A111C2-D8BF-E811-864D-005056AD2D14   \n",
       "919935   AB057000-E7D8-E711-B45B-005056AD2D14   \n",
       "561623   E8C83BD6-2C15-E711-AC9F-005056AD2D14   \n",
       "592345   79CEC772-D92F-E711-AC9F-005056AD2D14   \n",
       "1014822  59D28CD8-6468-E711-BE8E-005056AD2D14   \n",
       "\n",
       "                              ThreadMessageID  \\\n",
       "264513   12A111C2-D8BF-E811-864D-005056AD2D14   \n",
       "919935   B5057000-E7D8-E711-B45B-005056AD2D14   \n",
       "561623   F9C83BD6-2C15-E711-AC9F-005056AD2D14   \n",
       "592345   80CEC772-D92F-E711-AC9F-005056AD2D14   \n",
       "1014822  66D28CD8-6468-E711-BE8E-005056AD2D14   \n",
       "\n",
       "                                             ThreadSubject  \\\n",
       "264513        Lukning af virksomhed - Att. Steen Skivinger   \n",
       "919935            Din ret til supplerende dagpenge udløber   \n",
       "561623                  Ferie dagepenge optjeningsblanket.   \n",
       "592345                                       Dagepengesats   \n",
       "1014822  Nyt brev: Udfyld en blanket om din deltagelse ...   \n",
       "\n",
       "                                         ThreadMessageText  \\\n",
       "264513   \\nHej Steen\\nVi talte sammen i tlf her i formi...   \n",
       "919935   \\nKære Karin Arge\\nTak for dit brev. Det er je...   \n",
       "561623   \\n\\nHermed følger besked omkring mine ferie da...   \n",
       "592345   \\nHej,\\nMin ledighedserklæring er netop godken...   \n",
       "1014822  \\n\\n230854-1625\\n\\n\\nKære A-kasse\\n\\n\\nEfter l...   \n",
       "\n",
       "                                                      text  \\\n",
       "264513   vi talte sammen i tlf her i formiddag, jeg har...   \n",
       "919935   arge\\ntak for dit brev. det er jeg ked af at h...   \n",
       "561623   hermed følger besked omkring mine ferie dagpen...   \n",
       "592345   min ledighedserklæring er netop godkendt med e...   \n",
       "1014822  efter læsning af regelsæt har jeg vurderet , a...   \n",
       "\n",
       "                                            tokenized_text  \\\n",
       "264513   [blot, jeg_har, sammen, her, lå_som, denne_bes...   \n",
       "919935   [heller, fra_akassen, påtænker, kunne_anvende,...   \n",
       "561623   [dagpenge_fra, følger_besked, omkring_mine, fe...   \n",
       "592345   [fuldtidsarbejde, er_årsagen, sidste, netop, i...   \n",
       "1014822  [indbakke, ikke_kan, arbejde_mvh, pension, aka...   \n",
       "\n",
       "                                         stopwords_removed  \\\n",
       "264513   [blot, jeg_har, lå_som, denne_besked, info, be...   \n",
       "919935   [fra_akassen, påtænker, kunne_anvende, forbind...   \n",
       "561623   [dagpenge_fra, følger_besked, omkring_mine, fe...   \n",
       "592345   [fuldtidsarbejde, er_årsagen, sidste, netop, i...   \n",
       "1014822  [indbakke, ikke_kan, arbejde_mvh, pension, i_u...   \n",
       "\n",
       "                                           lemmatized_text  \\\n",
       "264513   [blot, jeg_har, lå_som, denne_besked, info, be...   \n",
       "919935   [fra_akassen, påtænker, kunne_anvende, forbind...   \n",
       "561623   [dagpenge_fra, følger_besked, omkring_mine, fe...   \n",
       "592345   [fuldtidsarbejde, er_årsagen, sidste, netop, i...   \n",
       "1014822  [indbakke, ikke_kan, arbejde_mvh, pension, i_u...   \n",
       "\n",
       "                                              stemmed_text  \n",
       "264513   [blot, jeg_har, lå_som, denne_besked, info, be...  \n",
       "919935   [fra_akas, påtænk, kunne_anv, forbindelse_vøns...  \n",
       "561623   [dagpenge_fra, følger_besked, omkring_min, fer...  \n",
       "592345   [fuldtidsarbejd, er_årsag, sidst, netop, ikke_...  \n",
       "1014822  [indbak, ikke_kan, arbejde_mvh, pension, i_und...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope_lda_sample[['ThreadID','ThreadMessageID','ThreadSubject','ThreadMessageText','text','tokenized_text','stopwords_removed','lemmatized_text','stemmed_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_lda_sample['text'][592345]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal number of topics for LDA\n",
    "#### K-means Elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Topwords\n",
    "Create a list of topwords from the entire dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-idf and document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define term frequency-inverse document frequency (tf-idf) vectorizer parameters and then convert the clean_content list into a tf-idf matrix.\n",
    "\n",
    "To get a Tf-idf matrix, first count word occurrences by request. This is transformed into a request-term matrix (dtm). This is also just called a term frequency matrix.\n",
    "\n",
    "Then apply the term frequency-inverse document frequency weighting: words that occur frequently within a request but not frequently within the corpus receive a higher weighting as these words are assumed to contain more meaning in relation to the request.\n",
    "\n",
    "A couple things to note about the parameters I define below:\n",
    "\n",
    "max_df: this is the maximum frequency within the request a given feature can have to be used in the tfi-idf matrix. If the term is in greater than 80% of the request it probably cares little meanining - rule of thumb (verify this)\n",
    "\n",
    "min_idf: this could be an integer (e.g. 5) and the term would have to be in at least 5 of the request to be considered. Here I pass 0.2; the term must be in at least 20% of the request. \n",
    "\n",
    "TEST THIS\n",
    "I found that if I allowed a lower min_df I ended up basing clustering on names--for example \"Michael\" or \"Tom\" are names found in several of the movies and the synopses use these names frequently, but the names carry no real meaning.\n",
    "\n",
    "ngram_range: this just means I'll look at unigrams, bigrams and trigrams. See n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top_words = [v for v in dictionary.values()]\n",
    "top_words = list(set(top_words))\n",
    "df_scope['OnlyTopWords'] = list(map(lambda doc: [word for word in doc if word in top_words], df_scope['stemmed_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No of top words: {} \".format(len(top_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "top_words, _ = remove_not_topwords(scope_lda_sample, df_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dictionary with words from df_scope (the total dataset) or scope_lda_sample (the sample size)\n",
    "# dictionary = Dictionary(documents=df_scope.stemmed_text.values)\n",
    "# #Make a BoW for every Besked\n",
    "# document_to_bow(df_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA preprocessing\n",
    "print(\"Found {} words.\".format(len(dictionary.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scope_lda_sample['clean_content'] = scope_lda_sample['OnlyTopWords'].apply(ListToString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_wordvector = TfidfVectorizer(\n",
    "                analyzer='word', \n",
    "                max_df=0.8, \n",
    "                min_df=5, \n",
    "#                 stop_words=stopwords.words('danish'),\n",
    "#                 ngram_range=(1,3)\n",
    "                ) \n",
    "\n",
    "#fit the tfidf_wordvector to clean_content\n",
    "tfidf_wordvector_maxtrix = tfidf_wordvector.fit_transform(scope_lda_sample.clean_content)\n",
    "print(tfidf_wordvector_maxtrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dist is defined as 1 - the cosine similarity of each request. Cosine similarity is measured against the tf-idf matrix and can be used to generate a measure of similarity between each request and the other request in the corpus (each clean_content among the total clean_content). Subtracting it from 1 provides cosine distance which I will use for plotting on a euclidean (2-dimensional) plane.\n",
    "\n",
    "Note that with dist it is possible to evaluate the similarity of any two or more clean_content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_wordvector_2d = tfidf_wordvector_maxtrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_range = 151\n",
    "increments = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distortions = []\n",
    "K = range(1,top_range,increments)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k, n_jobs=-1, random_state=0).fit(tfidf_wordvector_2d)\n",
    "    kmeanModel.fit(tfidf_wordvector_2d)\n",
    "    distortions.append(sum(np.min(cdist(tfidf_wordvector_2d, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / tfidf_wordvector_2d.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the elbow\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method: {4}. Showing the optimal k\\nSample Size: {0}, Top {1} Words, with increments of {2} from 0 to {3}'.format(sample_size, len(top_words), increments, top_range-1, data_scope_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model Training\n",
    "Latent Dirichlet Allocation (LDA) is generative approach in classifying texts. It is a three level hierarchical Bayesian model where it creates probabilities on word level, on document level and on corpus level (corpus means all documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to maximize the probability of the corpus in the training set.\n",
    "corpus = scope_lda_sample.bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input num_topics from the analysis above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#A multicore approach to decrease training time\n",
    "# https://radimrehurek.com/gensim/corpora/mmcorpus.html\n",
    "# ram_corpus = get_tmpfile(\"corpus_scope.mm\")\n",
    "# MmCorpus.serialize(ram_corpus, corpus)\n",
    "# mm = MmCorpus(ram_corpus)\n",
    "LDAmodel_scope = LdaMulticore(corpus=corpus,#mm,\n",
    "                        id2word=dictionary,\n",
    "                        num_topics=num_topics,\n",
    "                        workers=4,\n",
    "                        chunksize=5000,\n",
    "                        passes=50,\n",
    "                        alpha='asymmetric',\n",
    "                        random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model based on Udbetaling_topics-20_Sample-10000_WordCount-5000_RandomState-1_dataset-df_B dataset.\n",
      "\tSample Size: 10000,\n",
      "\tTop 5000 Words,\n",
      "\tNo of Topics 20\n"
     ]
    }
   ],
   "source": [
    "print(('LDA Model based on {3} dataset.\\n\\tSample Size: {0},\\n\\tTop {1} Words,\\n\\tNo of Topics {2}'.format(sample_size, len(dictionary.values()), num_topics, data_scope_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('data/model/{0}_LDAmodel_dictionary.pkl'.format(data_scope_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDAmodel_scope.save('data/model/{0}_LDAmodel'.format(data_scope_name))\n",
    "# LDAmodel_scope.save(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = LdaMulticore.load('data/model/{0}_LDAmodel'.format(data_scope_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_lda_features(lda_model, document):\n",
    "    \"\"\" Transforms a bag of words document to features.\n",
    "    It returns the proportion of how much each topic was\n",
    "    present in the document.\n",
    "    \"\"\"\n",
    "    topic_importances = lda_model.get_document_topics(document, minimum_probability=0)\n",
    "    topic_importances = np.array(topic_importances)\n",
    "    return topic_importances[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_lda_sample['lda_features'] = list(map(lambda doc: document_to_lda_features(LDAmodel_scope, doc), scope_lda_sample.bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic distributions and let's see some words that come with the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RequestTopicDistribution = scope_lda_sample['lda_features'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(1,1,figsize=(20,6))\n",
    "nr_top_bars = 3\n",
    "ax1.set_title(\"Request Topic distributions\", fontsize=16)\n",
    "\n",
    "for ax, distribution, color in zip([ax1], [RequestTopicDistribution], ['r']):\n",
    "    # Individual distribution barplots\n",
    "    ax.bar(range(len(distribution)), distribution, alpha=0.7)\n",
    "    rects = ax.patches\n",
    "    for i in np.argsort(distribution)[-nr_top_bars:]:\n",
    "        rects[i].set_color(color)\n",
    "        rects[i].set_alpha(1)\n",
    "\n",
    "fig.tight_layout(h_pad=3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect topics and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_and_prob(lda_model, topic_id, nr_top_words=7):\n",
    "    id_tuples = lda_model.print_topic(topic_id, topn=nr_top_words)\n",
    "    return id_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\tProb: 0.077, Words: 0.041*\"feri\" + 0.021*\"hold\" + 0.021*\"dag\" + 0.017*\"feriedagpeng\" + 0.014*\"feriepeng\".\n",
      "Topic: 1\tProb: 0.059, Words: 0.027*\"send\" + 0.018*\"mail\" + 0.011*\"du_har\" + 0.010*\"tak_for\" + 0.009*\"akademikernes_akas\".\n",
      "Topic: 2\tProb: 0.065, Words: 0.059*\"vedhæft\" + 0.042*\"frigørelsestilest\" + 0.029*\"kontrak\" + 0.029*\"send\" + 0.024*\"ansættelseskontrak\".\n",
      "Topic: 3\tProb: 0.045, Words: 0.027*\"modtag\" + 0.022*\"brev\" + 0.015*\"at_jeg\" + 0.013*\"dagpeng\" + 0.011*\"om_at\".\n",
      "Topic: 4\tProb: 0.053, Words: 0.038*\"ansøgning\" + 0.026*\"forbind\" + 0.025*\"forbindelse_med\" + 0.025*\"i_forbind\" + 0.024*\"ansøgning_om\".\n",
      "Topic: 5\tProb: 0.054, Words: 0.017*\"jeg_\" + 0.015*\"ansat\" + 0.010*\"at_jeg\" + 0.009*\"job\" + 0.009*\"start\".\n",
      "Topic: 6\tProb: 0.054, Words: 0.042*\"meld\" + 0.036*\"led\" + 0.017*\"mig_led\" + 0.016*\"jobn\" + 0.014*\"jobcent\".\n",
      "Topic: 7\tProb: 0.029, Words: 0.034*\"mul\" + 0.015*\"forlæng\" + 0.014*\"mulighed_for\" + 0.014*\"forsøg\" + 0.013*\"log\".\n",
      "Topic: 8\tProb: 0.027, Words: 0.017*\"par\" + 0.016*\"et_par\" + 0.013*\"prøv\" + 0.012*\"går\" + 0.011*\"forsøg\".\n",
      "Topic: 9\tProb: 0.020, Words: 0.021*\"jul\" + 0.018*\"nytår\" + 0.014*\"jul_og\" + 0.013*\"dagpeng\" + 0.013*\"og_nytår\".\n",
      "Topic: 10\tProb: 0.032, Words: 0.055*\"forhånd\" + 0.055*\"på_forhånd\" + 0.044*\"forhånd_tak\" + 0.042*\"hjælp\" + 0.026*\"tak_for\".\n",
      "Topic: 11\tProb: 0.083, Words: 0.017*\"fejl\" + 0.013*\"at_jeg\" + 0.012*\"fået\" + 0.011*\"jeg_ik\" + 0.011*\"en_fejl\".\n",
      "Topic: 12\tProb: 0.053, Words: 0.088*\"udfyld\" + 0.026*\"blanket\" + 0.026*\"blank\" + 0.021*\"ak\" + 0.018*\"har_udfyld\".\n",
      "Topic: 13\tProb: 0.086, Words: 0.008*\"at_d\" + 0.007*\"til_at\" + 0.006*\"arbejd\" + 0.006*\"at_jeg\" + 0.005*\"det_\".\n",
      "Topic: 14\tProb: 0.050, Words: 0.036*\"ydelseskort\" + 0.034*\"tim\" + 0.021*\"arbejd\" + 0.015*\"måned\" + 0.013*\"udfyld\".\n",
      "Topic: 15\tProb: 0.040, Words: 0.025*\"efterløn\" + 0.020*\"udbetaling\" + 0.013*\"tak_for\" + 0.010*\"pension\" + 0.010*\"går\".\n",
      "Topic: 16\tProb: 0.028, Words: 0.025*\"suppl\" + 0.024*\"ansøgning\" + 0.024*\"dagpeng\" + 0.020*\"supplerende_dagpeng\" + 0.015*\"brug\".\n",
      "Topic: 17\tProb: 0.039, Words: 0.026*\"jeg_\" + 0.021*\"tvivl\" + 0.019*\"i_tvivl\" + 0.017*\"tvivl_om\" + 0.016*\"udfyld\".\n",
      "Topic: 18\tProb: 0.066, Words: 0.018*\"dagpeng\" + 0.011*\"er_d\" + 0.011*\"arbejd\" + 0.010*\"job\" + 0.010*\"forhold\".\n",
      "Topic: 19\tProb: 0.041, Words: 0.020*\"gern\" + 0.013*\"jeg_vil\" + 0.012*\"virksom\" + 0.011*\"arbejd\" + 0.010*\"år\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(np.argsort(RequestTopicDistribution)[-num_topics:]):\n",
    "    top_words = get_topic_and_prob(LDAmodel_scope, x, 5) #get_topic_top_words(LDAmodel, x)\n",
    "    print(\"Topic: {0}\\tProb: {1:.3f}, Words: {2}.\".format(x, RequestTopicDistribution.item(x), top_words)) #(x, \", \".join(top_words)))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_topics(model, num_topics, topn=10):\n",
    "    word_dict = {};\n",
    "    for i in sorted(np.argsort(RequestTopicDistribution)[-num_topics:]):\n",
    "        words = model.show_topic(i, topn = topn);\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i)] = [i[0] for i in words];\n",
    "    return pd.DataFrame(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 00</th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "      <th>Topic # 09</th>\n",
       "      <th>Topic # 10</th>\n",
       "      <th>Topic # 11</th>\n",
       "      <th>Topic # 12</th>\n",
       "      <th>Topic # 13</th>\n",
       "      <th>Topic # 14</th>\n",
       "      <th>Topic # 15</th>\n",
       "      <th>Topic # 16</th>\n",
       "      <th>Topic # 17</th>\n",
       "      <th>Topic # 18</th>\n",
       "      <th>Topic # 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feri</td>\n",
       "      <td>send</td>\n",
       "      <td>vedhæft</td>\n",
       "      <td>modtag</td>\n",
       "      <td>ansøgning</td>\n",
       "      <td>jeg_</td>\n",
       "      <td>meld</td>\n",
       "      <td>mul</td>\n",
       "      <td>par</td>\n",
       "      <td>jul</td>\n",
       "      <td>forhånd</td>\n",
       "      <td>fejl</td>\n",
       "      <td>udfyld</td>\n",
       "      <td>at_d</td>\n",
       "      <td>ydelseskort</td>\n",
       "      <td>efterløn</td>\n",
       "      <td>suppl</td>\n",
       "      <td>jeg_</td>\n",
       "      <td>dagpeng</td>\n",
       "      <td>gern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hold</td>\n",
       "      <td>mail</td>\n",
       "      <td>frigørelsestilest</td>\n",
       "      <td>brev</td>\n",
       "      <td>forbind</td>\n",
       "      <td>ansat</td>\n",
       "      <td>led</td>\n",
       "      <td>forlæng</td>\n",
       "      <td>et_par</td>\n",
       "      <td>nytår</td>\n",
       "      <td>på_forhånd</td>\n",
       "      <td>at_jeg</td>\n",
       "      <td>blanket</td>\n",
       "      <td>til_at</td>\n",
       "      <td>tim</td>\n",
       "      <td>udbetaling</td>\n",
       "      <td>ansøgning</td>\n",
       "      <td>tvivl</td>\n",
       "      <td>er_d</td>\n",
       "      <td>jeg_vil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dag</td>\n",
       "      <td>du_har</td>\n",
       "      <td>kontrak</td>\n",
       "      <td>at_jeg</td>\n",
       "      <td>forbindelse_med</td>\n",
       "      <td>at_jeg</td>\n",
       "      <td>mig_led</td>\n",
       "      <td>mulighed_for</td>\n",
       "      <td>prøv</td>\n",
       "      <td>jul_og</td>\n",
       "      <td>forhånd_tak</td>\n",
       "      <td>fået</td>\n",
       "      <td>blank</td>\n",
       "      <td>arbejd</td>\n",
       "      <td>arbejd</td>\n",
       "      <td>tak_for</td>\n",
       "      <td>dagpeng</td>\n",
       "      <td>i_tvivl</td>\n",
       "      <td>arbejd</td>\n",
       "      <td>virksom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feriedagpeng</td>\n",
       "      <td>tak_for</td>\n",
       "      <td>send</td>\n",
       "      <td>dagpeng</td>\n",
       "      <td>i_forbind</td>\n",
       "      <td>job</td>\n",
       "      <td>jobn</td>\n",
       "      <td>forsøg</td>\n",
       "      <td>går</td>\n",
       "      <td>dagpeng</td>\n",
       "      <td>hjælp</td>\n",
       "      <td>jeg_ik</td>\n",
       "      <td>ak</td>\n",
       "      <td>at_jeg</td>\n",
       "      <td>måned</td>\n",
       "      <td>pension</td>\n",
       "      <td>supplerende_dagpeng</td>\n",
       "      <td>tvivl_om</td>\n",
       "      <td>job</td>\n",
       "      <td>arbejd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feriepeng</td>\n",
       "      <td>akademikernes_akas</td>\n",
       "      <td>ansættelseskontrak</td>\n",
       "      <td>om_at</td>\n",
       "      <td>ansøgning_om</td>\n",
       "      <td>start</td>\n",
       "      <td>jobcent</td>\n",
       "      <td>log</td>\n",
       "      <td>forsøg</td>\n",
       "      <td>og_nytår</td>\n",
       "      <td>tak_for</td>\n",
       "      <td>en_fejl</td>\n",
       "      <td>har_udfyld</td>\n",
       "      <td>det_</td>\n",
       "      <td>udfyld</td>\n",
       "      <td>går</td>\n",
       "      <td>brug</td>\n",
       "      <td>udfyld</td>\n",
       "      <td>forhold</td>\n",
       "      <td>år</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>optjent</td>\n",
       "      <td>brev</td>\n",
       "      <td>jeg_send</td>\n",
       "      <td>har_modtag</td>\n",
       "      <td>send</td>\n",
       "      <td>arbejd</td>\n",
       "      <td>at_jeg</td>\n",
       "      <td>kontak</td>\n",
       "      <td>lang</td>\n",
       "      <td>der_</td>\n",
       "      <td>for_hjælp</td>\n",
       "      <td>at_d</td>\n",
       "      <td>indsend</td>\n",
       "      <td>for_at</td>\n",
       "      <td>mit_ydelseskort</td>\n",
       "      <td>svar</td>\n",
       "      <td>ansøgning_om</td>\n",
       "      <td>er_i</td>\n",
       "      <td>jeg_</td>\n",
       "      <td>vil_g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>afhold</td>\n",
       "      <td>ring</td>\n",
       "      <td>har_vedhæft</td>\n",
       "      <td>haft</td>\n",
       "      <td>fremsend</td>\n",
       "      <td>stilling</td>\n",
       "      <td>jeg_</td>\n",
       "      <td>for_at</td>\n",
       "      <td>tid</td>\n",
       "      <td>arbejdsplad</td>\n",
       "      <td>kan_i</td>\n",
       "      <td>dagpeng</td>\n",
       "      <td>ar</td>\n",
       "      <td>mul</td>\n",
       "      <td>period</td>\n",
       "      <td>gå</td>\n",
       "      <td>kontak</td>\n",
       "      <td>hjælp</td>\n",
       "      <td>jeg_skal</td>\n",
       "      <td>selvstænd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feriedag</td>\n",
       "      <td>for_din</td>\n",
       "      <td>kopi</td>\n",
       "      <td>arbejd</td>\n",
       "      <td>ansøg</td>\n",
       "      <td>ansæt</td>\n",
       "      <td>dag</td>\n",
       "      <td>jeg_kan</td>\n",
       "      <td>gang</td>\n",
       "      <td>kollektiv</td>\n",
       "      <td>jeg_kan</td>\n",
       "      <td>måned</td>\n",
       "      <td>ledighedserklæring</td>\n",
       "      <td>jeg_</td>\n",
       "      <td>løn</td>\n",
       "      <td>udbetalt</td>\n",
       "      <td>i_har</td>\n",
       "      <td>i_kan</td>\n",
       "      <td>skal_jeg</td>\n",
       "      <td>jeg_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>udbetalt</td>\n",
       "      <td>vedhæft</td>\n",
       "      <td>vedkom</td>\n",
       "      <td>jeg_</td>\n",
       "      <td>befordringsgodtgør</td>\n",
       "      <td>da_jeg</td>\n",
       "      <td>melde_m</td>\n",
       "      <td>er_d</td>\n",
       "      <td>skriv</td>\n",
       "      <td>ferielukning</td>\n",
       "      <td>dagpeng</td>\n",
       "      <td>udbetalt</td>\n",
       "      <td>jeg_udfyld</td>\n",
       "      <td>der_</td>\n",
       "      <td>dagpeng</td>\n",
       "      <td>at_jeg</td>\n",
       "      <td>hvis_i</td>\n",
       "      <td>håb</td>\n",
       "      <td>hvis_jeg</td>\n",
       "      <td>vil_jeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>at_jeg</td>\n",
       "      <td>besked</td>\n",
       "      <td>rette_vedkom</td>\n",
       "      <td>ret</td>\n",
       "      <td>vedhæft</td>\n",
       "      <td>måned</td>\n",
       "      <td>på_jobn</td>\n",
       "      <td>muligt_at</td>\n",
       "      <td>find</td>\n",
       "      <td>mellem_jul</td>\n",
       "      <td>brug</td>\n",
       "      <td>der_</td>\n",
       "      <td>håb</td>\n",
       "      <td>håb</td>\n",
       "      <td>dag</td>\n",
       "      <td>jeg_vil</td>\n",
       "      <td>om_suppl</td>\n",
       "      <td>jeg_skal</td>\n",
       "      <td>søg</td>\n",
       "      <td>mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>period</td>\n",
       "      <td>at_du</td>\n",
       "      <td>arbejd</td>\n",
       "      <td>har_haft</td>\n",
       "      <td>aftal</td>\n",
       "      <td>kontrak</td>\n",
       "      <td>meldt_m</td>\n",
       "      <td>til_at</td>\n",
       "      <td>jeg_ik</td>\n",
       "      <td>spørgsmål</td>\n",
       "      <td>i_hjælp</td>\n",
       "      <td>dag</td>\n",
       "      <td>at_udfyld</td>\n",
       "      <td>jeg_ik</td>\n",
       "      <td>uge</td>\n",
       "      <td>på_efterløn</td>\n",
       "      <td>min_ansøgning</td>\n",
       "      <td>kan_hjælp</td>\n",
       "      <td>måned</td>\n",
       "      <td>jeg_g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ferie_i</td>\n",
       "      <td>kl</td>\n",
       "      <td>til_ret</td>\n",
       "      <td>tim</td>\n",
       "      <td>om_befordringsgodtgør</td>\n",
       "      <td>pr</td>\n",
       "      <td>jeg_meld</td>\n",
       "      <td>gang</td>\n",
       "      <td>jeg_</td>\n",
       "      <td>tro</td>\n",
       "      <td>mange_tak</td>\n",
       "      <td>står</td>\n",
       "      <td>det_</td>\n",
       "      <td>og_d</td>\n",
       "      <td>fået</td>\n",
       "      <td>barsel</td>\n",
       "      <td>oplysning</td>\n",
       "      <td>håber_i</td>\n",
       "      <td>for_at</td>\n",
       "      <td>hør</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jeg_hold</td>\n",
       "      <td>brug</td>\n",
       "      <td>vedhæftet_</td>\n",
       "      <td>oplys</td>\n",
       "      <td>virksomhedspraktik</td>\n",
       "      <td>jeg_blev</td>\n",
       "      <td>tilmeld</td>\n",
       "      <td>forkert</td>\n",
       "      <td>lang_tid</td>\n",
       "      <td>min_arbejdsplad</td>\n",
       "      <td>hjælpe_m</td>\n",
       "      <td>modtag</td>\n",
       "      <td>skema</td>\n",
       "      <td>tid</td>\n",
       "      <td>har_arbejd</td>\n",
       "      <td>gå_på</td>\n",
       "      <td>brug_for</td>\n",
       "      <td>om_jeg</td>\n",
       "      <td>mul</td>\n",
       "      <td>gerne_hav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>har_optjent</td>\n",
       "      <td>fået</td>\n",
       "      <td>kopi_af</td>\n",
       "      <td>bedt</td>\n",
       "      <td>min_ansøgning</td>\n",
       "      <td>jeg_ik</td>\n",
       "      <td>som_led</td>\n",
       "      <td>adgang</td>\n",
       "      <td>skal_jeg</td>\n",
       "      <td>regn</td>\n",
       "      <td>jeg_vil</td>\n",
       "      <td>udbetaling</td>\n",
       "      <td>arbejd</td>\n",
       "      <td>vid</td>\n",
       "      <td>ret</td>\n",
       "      <td>udbetaling_af</td>\n",
       "      <td>forbind</td>\n",
       "      <td>ydelseskort</td>\n",
       "      <td>i_d</td>\n",
       "      <td>sktilefri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ferie_fra</td>\n",
       "      <td>skrev</td>\n",
       "      <td>min_ansættelseskontrak</td>\n",
       "      <td>jeg_ik</td>\n",
       "      <td>sender_jeg</td>\n",
       "      <td>færd</td>\n",
       "      <td>afmeld</td>\n",
       "      <td>hurt</td>\n",
       "      <td>desvær</td>\n",
       "      <td>tro_og</td>\n",
       "      <td>gern</td>\n",
       "      <td>er_d</td>\n",
       "      <td>har_jeg</td>\n",
       "      <td>i_d</td>\n",
       "      <td>udbetalt</td>\n",
       "      <td>udbetaling_danmark</td>\n",
       "      <td>end</td>\n",
       "      <td>jeg_kan</td>\n",
       "      <td>i_forhold</td>\n",
       "      <td>ønsk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic # 00          Topic # 01              Topic # 02  Topic # 03  \\\n",
       "0           feri                send                 vedhæft      modtag   \n",
       "1           hold                mail       frigørelsestilest        brev   \n",
       "2            dag              du_har                 kontrak      at_jeg   \n",
       "3   feriedagpeng             tak_for                    send     dagpeng   \n",
       "4      feriepeng  akademikernes_akas      ansættelseskontrak       om_at   \n",
       "5        optjent                brev                jeg_send  har_modtag   \n",
       "6         afhold                ring             har_vedhæft        haft   \n",
       "7       feriedag             for_din                    kopi      arbejd   \n",
       "8       udbetalt             vedhæft                  vedkom        jeg_   \n",
       "9         at_jeg              besked            rette_vedkom         ret   \n",
       "10        period               at_du                  arbejd    har_haft   \n",
       "11       ferie_i                  kl                 til_ret         tim   \n",
       "12      jeg_hold                brug              vedhæftet_       oplys   \n",
       "13   har_optjent                fået                 kopi_af        bedt   \n",
       "14     ferie_fra               skrev  min_ansættelseskontrak      jeg_ik   \n",
       "\n",
       "               Topic # 04 Topic # 05 Topic # 06    Topic # 07 Topic # 08  \\\n",
       "0               ansøgning       jeg_       meld           mul        par   \n",
       "1                 forbind      ansat        led       forlæng     et_par   \n",
       "2         forbindelse_med     at_jeg    mig_led  mulighed_for       prøv   \n",
       "3               i_forbind        job       jobn        forsøg        går   \n",
       "4            ansøgning_om      start    jobcent           log     forsøg   \n",
       "5                    send     arbejd     at_jeg        kontak       lang   \n",
       "6                fremsend   stilling       jeg_        for_at        tid   \n",
       "7                   ansøg      ansæt        dag       jeg_kan       gang   \n",
       "8      befordringsgodtgør     da_jeg    melde_m          er_d      skriv   \n",
       "9                 vedhæft      måned    på_jobn     muligt_at       find   \n",
       "10                  aftal    kontrak    meldt_m        til_at     jeg_ik   \n",
       "11  om_befordringsgodtgør         pr   jeg_meld          gang       jeg_   \n",
       "12     virksomhedspraktik   jeg_blev    tilmeld       forkert   lang_tid   \n",
       "13          min_ansøgning     jeg_ik    som_led        adgang   skal_jeg   \n",
       "14             sender_jeg       færd     afmeld          hurt     desvær   \n",
       "\n",
       "         Topic # 09   Topic # 10  Topic # 11          Topic # 12 Topic # 13  \\\n",
       "0               jul      forhånd        fejl              udfyld       at_d   \n",
       "1             nytår   på_forhånd      at_jeg             blanket     til_at   \n",
       "2            jul_og  forhånd_tak        fået               blank     arbejd   \n",
       "3           dagpeng        hjælp      jeg_ik                  ak     at_jeg   \n",
       "4          og_nytår      tak_for     en_fejl          har_udfyld       det_   \n",
       "5              der_    for_hjælp        at_d             indsend     for_at   \n",
       "6       arbejdsplad        kan_i     dagpeng                  ar        mul   \n",
       "7         kollektiv      jeg_kan       måned  ledighedserklæring       jeg_   \n",
       "8      ferielukning      dagpeng    udbetalt          jeg_udfyld       der_   \n",
       "9        mellem_jul         brug        der_                 håb        håb   \n",
       "10        spørgsmål      i_hjælp         dag           at_udfyld     jeg_ik   \n",
       "11              tro    mange_tak        står                det_       og_d   \n",
       "12  min_arbejdsplad     hjælpe_m      modtag               skema        tid   \n",
       "13             regn      jeg_vil  udbetaling              arbejd        vid   \n",
       "14           tro_og         gern        er_d             har_jeg        i_d   \n",
       "\n",
       "         Topic # 14          Topic # 15           Topic # 16   Topic # 17  \\\n",
       "0       ydelseskort            efterløn                suppl         jeg_   \n",
       "1               tim          udbetaling            ansøgning        tvivl   \n",
       "2            arbejd             tak_for              dagpeng      i_tvivl   \n",
       "3             måned             pension  supplerende_dagpeng     tvivl_om   \n",
       "4            udfyld                 går                 brug       udfyld   \n",
       "5   mit_ydelseskort                svar         ansøgning_om         er_i   \n",
       "6            period                  gå               kontak        hjælp   \n",
       "7               løn            udbetalt                i_har        i_kan   \n",
       "8           dagpeng              at_jeg               hvis_i          håb   \n",
       "9               dag             jeg_vil             om_suppl     jeg_skal   \n",
       "10              uge         på_efterløn        min_ansøgning    kan_hjælp   \n",
       "11             fået              barsel            oplysning      håber_i   \n",
       "12       har_arbejd               gå_på             brug_for       om_jeg   \n",
       "13              ret       udbetaling_af              forbind  ydelseskort   \n",
       "14         udbetalt  udbetaling_danmark                  end      jeg_kan   \n",
       "\n",
       "   Topic # 18 Topic # 19  \n",
       "0     dagpeng       gern  \n",
       "1        er_d    jeg_vil  \n",
       "2      arbejd    virksom  \n",
       "3         job     arbejd  \n",
       "4     forhold         år  \n",
       "5        jeg_      vil_g  \n",
       "6    jeg_skal  selvstænd  \n",
       "7    skal_jeg       jeg_  \n",
       "8    hvis_jeg    vil_jeg  \n",
       "9         søg        mul  \n",
       "10      måned      jeg_g  \n",
       "11     for_at        hør  \n",
       "12        mul  gerne_hav  \n",
       "13        i_d  sktilefri  \n",
       "14  i_forhold       ønsk  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topics(LDAmodel_scope, num_topics,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topic_names = {\n",
    "    0:'Ferie og feriepenge',\n",
    "    1:'Sendt oplysninger til AKA',\n",
    "    2:'Ansættelseskontrakt eller frigørelse',\n",
    "    3:'Spørgsmål om dagpenge',\n",
    "    4:'Ansøgning om befordring',\n",
    "    5:'Har fået job',\n",
    "    6:'Meld ledig',\n",
    "    8:'Noget med tid*',\n",
    "    9:'Dagpenge mellem jul og nytår',\n",
    "    11:'Fejl ved dagpenge',\n",
    "    12:'Spørgsmål til blanket',\n",
    "    14:'Ydelseskort',\n",
    "    15:'Pension og Efterløn',\n",
    "    16:'Supplerende dagpenge',\n",
    "    19:'Spørgsmål om beskæftigelse'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963647    0B2DEE77-6947-E711-BE8E-005056AD2D14\n",
      "Name: ThreadMessageID, dtype: object 963647    har forelæst fire timer på mph uddannelsen i public health i maj og skal undervise 6 timer 14. juni.\\nman får løn for 2,5 timers forberedelsestid pr forelæsning.\\njeg vedhæfter den dokumentation j...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "document = scope_lda_sample.sample(1)\n",
    "doc_id = document['ThreadMessageID']\n",
    "unseen_document = document['text']\n",
    "print(doc_id, unseen_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3476802, 'Ydelseskort', '0.036*\"ydelseskort\" + 0.034*\"tim\" + 0.021*\"arbejd\" + 0.015*\"måned\" + 0.013*\"udfyld\"')\n"
     ]
    }
   ],
   "source": [
    "# Test function and prediction\n",
    "print(lda_predict_string(unseen_document, LDAmodel_scope, dictionary,lda_topic_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = dictionary.doc2bow(lda_preprocess_string(unseen_document))\n",
    "for index, score in sorted(LDAmodel_scope[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, LDAmodel_scope.print_topic(index, 5)))\n",
    "\n",
    "# index, score = sorted(LDAmodel_scope[bow_vector], key=lambda tup: -1*tup[1])[0]\n",
    "# print(\"Score: {}\\t Topic: {}\".format(score, LDAmodel_scope.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict topics on data\n",
    "Per every row in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_prediction(df,lda_model, lda_topic_name_list):\n",
    "    \" Make the following function into a function that returns the pred_label and pred_prob below\"\n",
    "#     for index, score in sorted(LDAmodel_lang[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "#         print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))\n",
    "    \n",
    "    df['bow'] = list(map(lambda doc: dictionary.doc2bow(doc), df.stemmed_text))\n",
    "    df['prediction'] = df['bow'].apply(PredictTopicFromBOW,lda_model=lda_model, lda_topic_name_list=lda_topic_name_list)\n",
    "    df[['pred_probability','pred_index','pred_label']] = pd.DataFrame(df.prediction.values.tolist(), index= df.index)\n",
    "    df.drop(['prediction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lda_predict_df(df_scope,LDAmodel_scope, dictionary, lda_topic_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data with prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scope.to_pickle('data/AKA_{0}_with_prediction.pkl'.format(data_scope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load to MS SQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_raw = pd.read_pickle('data/AKA_rawdata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lipht_lda import df_lda_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_lda_preprocessing(df_raw, 'ThreadMessageText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_pickle('data/AKA_rawdata_df_lda_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lda_prediction(df_raw,LDAmodel_scope, lda_topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw[df_raw['pred_label']=='English']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_with_language = df_raw[['ThreadID','ThreadMessageID','ThreadMessageText','text','pred_label','pred_probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_with_language.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_with_language.to_csv('lang_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = \"mssql+pyodbc:///?odbc_connect={}\".format(urllib.parse.quote_plus(\"DRIVER=ODBC Driver 13 for SQL Server;SERVER={0};PORT=1433;DATABASE={1};UID={2};PWD={3};TDS_Version=8.0;\".format(server, db, user, password)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'test':[1,2,3]}) #'te','te','te'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "\n",
    "params = urllib.parse.quote_plus(r'DRIVER={SQL Server};SERVER=LIPHT-VM-01;DATABASE=Akademikernes_MSCRM_addition;Trusted_Connection=yes')\n",
    "conn_str = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "\n",
    "test.to_sql(name='Test',con=engine , schema='input', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_pickle('data/AKA_rawdata_with_language.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:akademikernes_diagnostic]",
   "language": "python",
   "name": "conda-env-akademikernes_diagnostic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
